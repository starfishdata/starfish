{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f88eFnqYe4hL"
      },
      "source": [
<<<<<<< Updated upstream:examples/usecases/math_data_gen.ipynb
        "# Google Colab Version: [Open this notebook in Google Colab](https://colab.research.google.com/github/starfishdata/starfish/blob/main/examples/usecases/math_data_gen.ipynb)\n"
=======
        "# Goal\n",
        "\n",
        "> Explore to using synthetic data to finetune or distill a small model to achieve the same performance on the AIME benchmark\n",
        "\n",
        "\n",
        "1. Pick a small model (Preferrable pick one from hyperbolic)\n",
        "2. A process to evaluation on AIME benchmark\n",
        "3. Finetune (SFT / GRPO) - GRPO\n",
        "4. Generate synthetic data\n",
        "\n",
        "Iterate until we achieve the good performance on AIME"
>>>>>>> Stashed changes:examples/usecases/math_data_gen_template.ipynb
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gavohralH7RQ"
      },
      "source": [
        "# Strategy\n",
        "\n",
        "#### Step 0: Topic Generation\n",
        "What: Generate focused math topics (e.g., modular arithmetic, binomial coefficients).\n",
        "Why: Ensures diverse domain coverage across AIME-style questions.\n",
        "\n",
        "#### Step 0a: Topic splits for variety\n",
        "\n",
        "500 topics\n",
        "\n",
        "Each topic:\n",
        "\n",
        " - 2 problems → Long CoT\n",
        " - 8 problems → Short CoT\n",
        "\n",
        "Total = 500 × 10 = 5000 problems\n",
        "\n",
        "Why: Every topic has a healthy mix of simple (short CoT) and complex (long CoT) thinking. You avoid domain mismatch — if you separate topics, the model might learn that \"some topics are hard\" and \"some are easy,\" which is unnatural.\n",
        "\n",
        "\n",
        "#### Step 1: Problem Generation\n",
        "What: Generate an AIME-style math problem for each topic.\n",
        "Why: Keeps problem structure realistic and solvable in 3–6 steps.\n",
        "\n",
        "#### Step 2: Python Execution Verification\n",
        "What: Convert CoT to Python code, execute it, and compare result to final answer.\n",
        "Why: Ensures strict correctness without relying on model judgment.\n",
        "\n",
        "#### Step 3: Long CoT Generation OR Short CoT\n",
        "What: Use a large model to generate detailed reasoning.\n",
        "Why: Captures rich logical steps for use in training or Mix Distillation.\n",
        "\n",
        "\n",
        "#### Step 4: Feedback and Rewrite (if failed for each)\n",
        "What: If CoT fails verification, generate a revised version using feedback.\n",
        "Why: Improves clarity and correctness while preserving reasoning structure.\n",
        "\n",
        "#### Step 6: Format Final Output\n",
        "What: Package the problem, CoT, final answer, and metadata into structured JSON.\n",
        "Why: Prepares for downstream fine-tuning with clear supervision.\n",
        "\n",
        "\n",
        "Inspiration: https://arxiv.org/pdf/2502.12143"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQBenxiDPRMv"
      },
      "source": [
        "# Implementation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXcEExUEgWWs"
      },
      "source": [
        "## Starfish pull from pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gTk3EIHkPtZK",
        "outputId": "7a335444-e90b-46d6-c6de-4732ea466cd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: starfish-core in /usr/local/lib/python3.11/dist-packages (0.1.1)\n",
            "Requirement already satisfied: aiofiles<25.0.0,>=24.1.0 in /usr/local/lib/python3.11/dist-packages (from starfish-core) (24.1.0)\n",
            "Requirement already satisfied: aiosqlite<0.22.0,>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from starfish-core) (0.21.0)\n",
            "Requirement already satisfied: cachetools<6.0.0,>=5.5.2 in /usr/local/lib/python3.11/dist-packages (from starfish-core) (5.5.2)\n",
            "Requirement already satisfied: cloudpickle<3.0.0,>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from starfish-core) (2.2.1)\n",
            "Requirement already satisfied: cryptography>=44.0.1 in /usr/local/lib/python3.11/dist-packages (from starfish-core) (44.0.3)\n",
            "Requirement already satisfied: litellm<2.0.0,>=1.65.1 in /usr/local/lib/python3.11/dist-packages (from starfish-core) (1.67.0)\n",
            "Requirement already satisfied: loguru<0.8.0,>=0.7.3 in /usr/local/lib/python3.11/dist-packages (from starfish-core) (0.7.3)\n",
            "Requirement already satisfied: nest_asyncio<2.0.0,>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from starfish-core) (1.6.0)\n",
            "Requirement already satisfied: ollama<0.5.0,>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from starfish-core) (0.4.8)\n",
            "Requirement already satisfied: posthog<4.0.0,>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from starfish-core) (3.25.0)\n",
            "Requirement already satisfied: psutil<8.0.0,>=7.0.0 in /usr/local/lib/python3.11/dist-packages (from starfish-core) (7.0.0)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from starfish-core) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from starfish-core) (4.13.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=44.0.1->starfish-core) (1.17.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from litellm<2.0.0,>=1.65.1->starfish-core) (3.11.15)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from litellm<2.0.0,>=1.65.1->starfish-core) (8.1.8)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from litellm<2.0.0,>=1.65.1->starfish-core) (0.28.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm<2.0.0,>=1.65.1->starfish-core) (8.7.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm<2.0.0,>=1.65.1->starfish-core) (3.1.6)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from litellm<2.0.0,>=1.65.1->starfish-core) (4.23.0)\n",
            "Requirement already satisfied: openai>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from litellm<2.0.0,>=1.65.1->starfish-core) (1.77.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from litellm<2.0.0,>=1.65.1->starfish-core) (2.11.4)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from litellm<2.0.0,>=1.65.1->starfish-core) (0.9.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from litellm<2.0.0,>=1.65.1->starfish-core) (0.21.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.7 in /usr/local/lib/python3.11/dist-packages (from posthog<4.0.0,>=3.11.0->starfish-core) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog<4.0.0,>=3.11.0->starfish-core) (1.17.0)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog<4.0.0,>=3.11.0->starfish-core) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog<4.0.0,>=3.11.0->starfish-core) (2.2.1)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.11/dist-packages (from posthog<4.0.0,>=3.11.0->starfish-core) (2.9.0.post0)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog<4.0.0,>=3.11.0->starfish-core) (1.9.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=44.0.1->starfish-core) (2.22)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm<2.0.0,>=1.65.1->starfish-core) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm<2.0.0,>=1.65.1->starfish-core) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm<2.0.0,>=1.65.1->starfish-core) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm<2.0.0,>=1.65.1->starfish-core) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->litellm<2.0.0,>=1.65.1->starfish-core) (0.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm<2.0.0,>=1.65.1->starfish-core) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm<2.0.0,>=1.65.1->starfish-core) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.65.1->starfish-core) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.65.1->starfish-core) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.65.1->starfish-core) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.65.1->starfish-core) (0.24.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->litellm<2.0.0,>=1.65.1->starfish-core) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->litellm<2.0.0,>=1.65.1->starfish-core) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->litellm<2.0.0,>=1.65.1->starfish-core) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->litellm<2.0.0,>=1.65.1->starfish-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->litellm<2.0.0,>=1.65.1->starfish-core) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->litellm<2.0.0,>=1.65.1->starfish-core) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.7->posthog<4.0.0,>=3.11.0->starfish-core) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.7->posthog<4.0.0,>=3.11.0->starfish-core) (2.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.7.0->litellm<2.0.0,>=1.65.1->starfish-core) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm<2.0.0,>=1.65.1->starfish-core) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm<2.0.0,>=1.65.1->starfish-core) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm<2.0.0,>=1.65.1->starfish-core) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm<2.0.0,>=1.65.1->starfish-core) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm<2.0.0,>=1.65.1->starfish-core) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm<2.0.0,>=1.65.1->starfish-core) (1.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers->litellm<2.0.0,>=1.65.1->starfish-core) (0.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm<2.0.0,>=1.65.1->starfish-core) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm<2.0.0,>=1.65.1->starfish-core) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm<2.0.0,>=1.65.1->starfish-core) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm<2.0.0,>=1.65.1->starfish-core) (6.0.2)\n",
            "Requirement already satisfied: liteLLM==1.67.0 in /usr/local/lib/python3.11/dist-packages (1.67.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from liteLLM==1.67.0) (3.11.15)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from liteLLM==1.67.0) (8.1.8)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from liteLLM==1.67.0) (0.28.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from liteLLM==1.67.0) (8.7.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from liteLLM==1.67.0) (3.1.6)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from liteLLM==1.67.0) (4.23.0)\n",
            "Requirement already satisfied: openai>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from liteLLM==1.67.0) (1.77.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from liteLLM==1.67.0) (2.11.4)\n",
            "Requirement already satisfied: python-dotenv>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from liteLLM==1.67.0) (1.1.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from liteLLM==1.67.0) (0.9.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from liteLLM==1.67.0) (0.21.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->liteLLM==1.67.0) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->liteLLM==1.67.0) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->liteLLM==1.67.0) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->liteLLM==1.67.0) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->liteLLM==1.67.0) (0.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->liteLLM==1.67.0) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->liteLLM==1.67.0) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->liteLLM==1.67.0) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->liteLLM==1.67.0) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->liteLLM==1.67.0) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->liteLLM==1.67.0) (0.24.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->liteLLM==1.67.0) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->liteLLM==1.67.0) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->liteLLM==1.67.0) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->liteLLM==1.67.0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->liteLLM==1.67.0) (4.13.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->liteLLM==1.67.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->liteLLM==1.67.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->liteLLM==1.67.0) (0.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.7.0->liteLLM==1.67.0) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.7.0->liteLLM==1.67.0) (2.32.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->liteLLM==1.67.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->liteLLM==1.67.0) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->liteLLM==1.67.0) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->liteLLM==1.67.0) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->liteLLM==1.67.0) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->liteLLM==1.67.0) (1.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers->liteLLM==1.67.0) (0.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->liteLLM==1.67.0) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->liteLLM==1.67.0) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->liteLLM==1.67.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->liteLLM==1.67.0) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken>=0.7.0->liteLLM==1.67.0) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken>=0.7.0->liteLLM==1.67.0) (2.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install starfish-core\n",
        "!pip install liteLLM==1.67.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBNBslDchCYx"
      },
      "source": [
        "## Other packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PaIo-J-lBdKl",
        "outputId": "45f0f8ad-df57-4641-f6f6-98e6bc43ce8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai-agents\n",
            "  Downloading openai_agents-0.0.14-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting griffe<2,>=1.5.6 (from openai-agents)\n",
            "  Downloading griffe-1.7.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting mcp<2,>=1.6.0 (from openai-agents)\n",
            "  Downloading mcp-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting openai>=1.76.0 (from openai-agents)\n",
            "  Downloading openai-1.77.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic<3,>=2.10 in /usr/local/lib/python3.11/dist-packages (from openai-agents) (2.11.4)\n",
            "Requirement already satisfied: requests<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from openai-agents) (2.32.3)\n",
            "Collecting types-requests<3,>=2.0 (from openai-agents)\n",
            "  Downloading types_requests-2.32.0.20250328-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from openai-agents) (4.13.2)\n",
            "Collecting colorama>=0.4 (from griffe<2,>=1.5.6->openai-agents)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: anyio>=4.5 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.6.0->openai-agents) (4.9.0)\n",
            "Collecting httpx-sse>=0.4 (from mcp<2,>=1.6.0->openai-agents)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: httpx>=0.27 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.6.0->openai-agents) (0.28.1)\n",
            "Collecting pydantic-settings>=2.5.2 (from mcp<2,>=1.6.0->openai-agents)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting python-multipart>=0.0.9 (from mcp<2,>=1.6.0->openai-agents)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting sse-starlette>=1.6.1 (from mcp<2,>=1.6.0->openai-agents)\n",
            "  Downloading sse_starlette-2.3.4-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting starlette>=0.27 (from mcp<2,>=1.6.0->openai-agents)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting uvicorn>=0.23.1 (from mcp<2,>=1.6.0->openai-agents)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.76.0->openai-agents) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.76.0->openai-agents) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.76.0->openai-agents) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai>=1.76.0->openai-agents) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.10->openai-agents) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.10->openai-agents) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.10->openai-agents) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openai-agents) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openai-agents) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openai-agents) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openai-agents) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27->mcp<2,>=1.6.0->openai-agents) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27->mcp<2,>=1.6.0->openai-agents) (0.16.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings>=2.5.2->mcp<2,>=1.6.0->openai-agents) (1.1.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.23.1->mcp<2,>=1.6.0->openai-agents) (8.1.8)\n",
            "Downloading openai_agents-0.0.14-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading griffe-1.7.3-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mcp-1.7.1-py3-none-any.whl (100 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.4/100.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.77.0-py3-none-any.whl (662 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m662.0/662.0 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.0.20250328-py3-none-any.whl (20 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading sse_starlette-2.3.4-py3-none-any.whl (10 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvicorn, types-requests, python-multipart, httpx-sse, colorama, starlette, griffe, sse-starlette, pydantic-settings, openai, mcp, openai-agents\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.75.0\n",
            "    Uninstalling openai-1.75.0:\n",
            "      Successfully uninstalled openai-1.75.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "litellm 1.68.1 requires openai<1.76.0,>=1.68.2, but you have openai 1.77.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed colorama-0.4.6 griffe-1.7.3 httpx-sse-0.4.0 mcp-1.7.1 openai-1.77.0 openai-agents-0.0.14 pydantic-settings-2.9.1 python-multipart-0.0.20 sse-starlette-2.3.4 starlette-0.46.2 types-requests-2.32.0.20250328 uvicorn-0.34.2\n"
          ]
        }
      ],
      "source": [
        "pip install openai-agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HmbElAYeiybQ",
        "outputId": "3e6538c9-9e8f-44ae-81b9-170a1a707177"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
            "dask 2024.12.1 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.6.0 dill-0.3.8 fsspec-2025.3.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPcC90Dugf55"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "c4BOMHBaPuBz"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "from starfish import data_factory, StructuredLLM\n",
        "import os\n",
        "from agents import Agent, Runner, function_tool, ModelSettings, ReasoningItem\n",
        "from agents.agent_output import AgentOutputSchema\n",
        "from pydantic import BaseModel\n",
        "\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XpM6nSrIIWgC"
      },
      "outputs": [],
      "source": [
        "# Define your default parameters\n",
        "DEFAULT_CONFIG = {\n",
        "    \"max_concurrency\": 100,\n",
        "    \"task_runner_timeout\": 200,  # TASK_RUNNER_TIMEOUT\n",
        "    \"job_run_stop_threshold\": 100,  # JOB_RUN_STOP_THRESHOLD\n",
        "    \"dead_queue_threshold\": 2  # DEAD_QUEUE_THRESHOLD\n",
        "}\n",
        "\n",
        "def data_factory_with_default(**override_kwargs):\n",
        "    \"\"\"\n",
        "    Creates a data_factory decorator with default parameters.\n",
        "    Any parameters passed as kwargs will override the defaults.\n",
        "    \"\"\"\n",
        "    # Merge default config with any overrides\n",
        "    kwargs = {**DEFAULT_CONFIG, **override_kwargs}\n",
        "\n",
        "    # Return a decorator function\n",
        "    def decorator(func):\n",
        "        # Apply the data_factory decorator with our parameters\n",
        "        return data_factory(**kwargs)(func)\n",
        "\n",
        "    return decorator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "id": "-WCJYDbwPdTL"
      },
      "outputs": [],
      "source": [
        "model_name_used = 'openai/gpt-4.1-mini'\n",
        "reasoning_model = 'o4-mini'\n",
        "google_reasoning_model = \"gemini/gemini-2.5-flash-preview-04-17\"\n",
        "\n",
        "\n",
        "@data_factory_with_default()\n",
        "async def generate_topic(num_records):\n",
        "    prompt = \"\"\"\n",
        "List unique math topics that are commonly tested on the American Invitational Mathematics Examination (AIME).\n",
        "\n",
        "Ensure broad coverage across major mathematical areas, including but not limited to:\n",
        "- Algebra (factoring, solving equations, inequalities, polynomials)\n",
        "- Geometry (plane geometry, coordinate geometry, three-dimensional geometry)\n",
        "- Number Theory (divisibility, modular arithmetic, primes)\n",
        "- Counting and Probability (combinatorics, probability theory)\n",
        "- Intermediate Algebra (advanced factoring techniques, sequences, series, inequalities)\n",
        "- Precalculus (functions, trigonometry, graphing)\n",
        "- Calculus (limits, derivatives, integrals)\n",
        "\n",
        "Additionally, include specialized and niche topics commonly seen in competition settings (e.g., barycentric coordinates, generating functions).\n",
        "\n",
        "Focus especially on topics and subtopics that have appeared frequently between 2020 and 2025.\n",
        "\n",
        "Each topic should be:\n",
        "- Granular enough to guide the creation of specific math problems\n",
        "- Distinct enough to avoid excessive overlap with others\n",
        "- Competitive enough to match AIME difficulty standards\n",
        "    \"\"\"\n",
        "    model = StructuredLLM(\n",
        "        model_name=model_name_used,\n",
        "        prompt=prompt,\n",
        "        output_schema=[{\"name\": \"topic\", \"type\": \"str\", \"required\": True}]\n",
        "    )\n",
        "    return (await model.run(num_records=num_records)).data\n",
        "\n",
        "@data_factory_with_default()\n",
        "async def generate_sub_topics(topic):\n",
        "    prompt = \"\"\"\n",
        "    or the math topic {{topic}}, list detailed subtopics or specific areas that are commonly tested in AIME (American Invitational Mathematics Examination) problems.\n",
        "    Focus on important subcategories, typical problem types, and any nuanced areas students should be familiar with.\n",
        "    Keep the subtopics concise, specific, and directly related to what appears on AIME problems, especially from 2020–2025.\n",
        "    \"\"\"\n",
        "    model = StructuredLLM(\n",
        "        model_name=model_name_used,\n",
        "        prompt=prompt,\n",
        "        output_schema=[{\"name\": \"topic\", \"type\": \"str\", \"required\": True}]\n",
        "    )\n",
        "    return (await model.run(topic=topic, num_records=12)).data\n",
        "\n",
        "@data_factory_with_default()\n",
        "async def generate_problem(topic):\n",
        "    prompt = \"\"\"\n",
        "Create a AIME-style math competition problem in the topic of {{topic}}.\n",
        "\n",
        "Requirements:\n",
        "\n",
        "1. The problem should be original and adhere to AIME difficulty (appropriate for high school students aiming for USAMO qualification).\n",
        "2. It must be solvable in 3 to 6 logical steps, without requiring computational brute force.\n",
        "3. Emphasize creativity, clean setup, and an elegant path to the solution.\n",
        "4. Use clear and concise language. No extraneous details.\n",
        "5. Do not include the answer or any solution steps.\n",
        "6. Return only the problem text.\n",
        "    \"\"\"\n",
        "    model = StructuredLLM(\n",
        "        model_name=google_reasoning_model,\n",
        "        prompt=prompt,\n",
        "        output_schema=[{\"name\": \"problem\", \"type\": \"str\", \"required\": True}, {\"name\": \"topic\", \"type\": \"str\", \"required\": True}]\n",
        "    )\n",
        "    return (await model.run(topic=topic)).data\n",
        "\n",
        "# Step 1: Define your desired structured output\n",
        "class CoTSchema(BaseModel):\n",
        "    problem: str\n",
        "    topic: str\n",
        "    answer: str\n",
        "    reasoning: str\n",
        "\n",
        "@data_factory_with_default()\n",
        "async def answer_long_cot(problem, topic):\n",
        "    prompt = f\"\"\"Solve the following problem using a **long and detailed chain of thought**.\n",
        "    Include multiple reasoning steps, explore different possibilities if relevant, and explain why each step is taken.\n",
        "    Incorporate reflective thinking, justify your decisions, and reference any important theorems or concepts.\n",
        "    Your reasoning should be extended and elaborate, not skipping any intermediate calculations or logic.\n",
        "\n",
        "    Problem: {problem}\n",
        "\n",
        "    Final Answer:\"\"\"\n",
        "\n",
        "\n",
        "    my_agent = Agent(\n",
        "      name=\"Problem solver\",\n",
        "      output_type=CoTSchema,\n",
        "      model=model_name_used,\n",
        "      # model_settings=ModelSettings(reasoning={\"effort\": \"high\", \"summary\": \"detailed\"}),\n",
        "    )\n",
        "\n",
        "    sample_run = await Runner.run(\n",
        "      my_agent,\n",
        "      input=prompt\n",
        "    )\n",
        "\n",
        "    output = sample_run.final_output.model_dump()\n",
        "    output[\"cot_type\"] = \"long\"\n",
        "    output[\"topic\"] = topic\n",
        "    return [output]\n",
        "\n",
        "\n",
        "@data_factory_with_default()\n",
        "async def answer_short_cot(problem, topic):\n",
        "    prompt = \"\"\"Solve the following problem using a **concise chain of thought**.\n",
        "    Clearly and directly walk through the key reasoning steps needed to arrive at the answer.\n",
        "    Avoid unnecessary elaboration or backtracking—keep it efficient, but logically sound.\n",
        "\n",
        "    Problem: {{problem}}\n",
        "\n",
        "    Final Answer:\"\"\"\n",
        "\n",
        "    # Create StructuredLLM instance instead of Agent\n",
        "    solver = StructuredLLM(\n",
        "        model_name=google_reasoning_model,\n",
        "        prompt=prompt,\n",
        "        output_schema=CoTSchema\n",
        "      )\n",
        "\n",
        "    # Use run() method and pass the variables\n",
        "    # print(\"START \" + str(output))\n",
        "\n",
        "    result = await solver.run(problem=problem)\n",
        "    # The result.data contains the structured output\n",
        "    output = result.data[0]  # Get first item since run() returns a list\n",
        "    # print(\"DONE \" + str(output))\n",
        "    output[\"cot_type\"] = \"short\"\n",
        "    output[\"topic\"] = topic\n",
        "    return [output]\n",
        "\n",
        "# Step 1: Define your desired structured output\n",
        "class CodeExecutorSchema(BaseModel):\n",
        "    calculated_result: str\n",
        "    topic: str\n",
        "    problem: str\n",
        "    code: str\n",
        "    reasoning: str\n",
        "    finished_run: bool\n",
        "\n",
        "class AnswerVerfierSchema(BaseModel):\n",
        "    verified: bool\n",
        "\n",
        "# Schemas\n",
        "class CodeGeneratorSchema(BaseModel):\n",
        "    generated_code: str\n",
        "\n",
        "class CodeCritiqueSchema(BaseModel):\n",
        "    critique: str\n",
        "    alignment_issues: list[str]\n",
        "    edge_cases_missing: list[str]\n",
        "    complexity_assessment: str\n",
        "\n",
        "class CodeRegeneratorSchema(BaseModel):\n",
        "    improved_code: str\n",
        "    improvements_made: list[str]\n",
        "\n",
        "\n",
        "@data_factory_with_default()\n",
        "async def generate_initial_code(problem, reasoning, topic, answer, cot_type):\n",
        "    initial_code_prompt = \"\"\"\n",
        "    You are an expert Python developer tasked with converting an AIME-style math problem and its solution reasoning into executable Python code.\n",
        "\n",
        "    Problem:\n",
        "    {{problem}}\n",
        "\n",
        "    Chain of Thought Solution:\n",
        "    {{reasoning}}\n",
        "\n",
        "    **generated_code:**\n",
        "    ```python\n",
        "    # Python code implementation of the AIME problem and solution\n",
        "\n",
        "    # Follow the exact reasoning steps shown in the Chain of Thought\n",
        "    # Use appropriate Python libraries (math, itertools, etc.) if needed\n",
        "    import math\n",
        "    import itertools\n",
        "    # import numpy as np # Include if needed based on the problem\n",
        "\n",
        "    # Include comments explaining key steps\n",
        "    # Be mathematically rigorous without shortcuts\n",
        "    # Is self-contained and can be executed independently\n",
        "\n",
        "    # --- Start of implementation ---\n",
        "    {code_placeholder} # This will be replaced with the generated code\n",
        "\n",
        "    # Assign final output to variable `calculated_result`\n",
        "    # Ensure that correct_solution is always assigned without relying on `if __name__ == \"__main__\"`\n",
        "    # Avoid using asserts for expected list sizes; use conditional checks instead.\n",
        "    # At the end of the code compare `calculated_result` with the `corect_answer` and assert that they match.\n",
        "    calculated_result == {{ correct_answer }}\n",
        "\n",
        "    # --- End of implementation ---\n",
        "    ```\n",
        "    \"\"\"\n",
        "\n",
        "    code_generator = StructuredLLM(\n",
        "        model_name=google_reasoning_model,\n",
        "        prompt=initial_code_prompt,\n",
        "        output_schema=CodeGeneratorSchema,\n",
        "    )\n",
        "\n",
        "    result = await code_generator.run(problem=problem, reasoning=reasoning, correct_answer=answer)\n",
        "    output = result.data[0]\n",
        "\n",
        "    return [{\n",
        "        \"initial_code\": output['generated_code'],\n",
        "        \"problem\": problem,\n",
        "        \"reasoning\": reasoning,\n",
        "        \"topic\": topic,\n",
        "        \"answer\": answer,\n",
        "        \"cot_type\": cot_type,\n",
        "    }]\n",
        "\n",
        "\n",
        "# Step 2: Data Factory → Critique generated code\n",
        "@data_factory_with_default()\n",
        "async def critique_generated_code(initial_code: str, problem: str, reasoning: str, topic: str, answer: str, cot_type: str):\n",
        "    critique_prompt = \"\"\"\n",
        "    Analyze the following Python code that solves an AIME math problem.\n",
        "    Evaluate it for:\n",
        "    1. Alignment with the original chain of thought reasoning\n",
        "    2. Mathematical rigor and absence of shortcuts\n",
        "    3. Missing edge cases or assumptions\n",
        "    4. Appropriate complexity level for an AIME problem\n",
        "\n",
        "    Problem:\n",
        "    {{problem}}\n",
        "\n",
        "    Chain of Thought:\n",
        "    {{reasoning}}\n",
        "\n",
        "    Generated Code:\n",
        "    {{initial_code}}\n",
        "    \"\"\"\n",
        "\n",
        "    code_critic = Agent(\n",
        "        name=\"Code Critic\",\n",
        "        output_type=CodeCritiqueSchema,\n",
        "        model=model_name_used\n",
        "    )\n",
        "\n",
        "    result = await Runner.run(code_critic, input=critique_prompt)\n",
        "\n",
        "    return [{\n",
        "        \"initial_code\": initial_code,\n",
        "        \"critique\": result.final_output.critique,\n",
        "        \"edge_cases_missing\": result.final_output.edge_cases_missing,\n",
        "        \"alignment_issues\": result.final_output.alignment_issues,\n",
        "        \"problem\": problem,\n",
        "        \"reasoning\": reasoning,\n",
        "        \"topic\": topic,\n",
        "        \"answer\": answer,\n",
        "        \"cot_type\": cot_type,\n",
        "    }]\n",
        "\n",
        "\n",
        "@data_factory_with_default()\n",
        "async def regenerate_code(initial_code: str, critique: str, edge_cases_missing: list[str], alignment_issues: list[str], problem: str, reasoning: str, topic: str, answer: str, cot_type: str):\n",
        "    regenerate_prompt = \"\"\"\n",
        "ou are an expert Python developer tasked with refining previously generated code for an AIME-style math problem based on a critique.\n",
        "\n",
        "Problem:\n",
        "{{problem}}\n",
        "\n",
        "Chain of Thought Solution:\n",
        "{{reasoning}}\n",
        "\n",
        "Initial Code (Requires Improvement):\n",
        "{{initial_code}}\n",
        "\n",
        "Critique Summary of Initial Code:\n",
        "{{critique}}\n",
        "\n",
        "Specific Issues Identified from Critique:\n",
        "- Missing Edge Cases: {{edge_cases_missing}}\n",
        "- Alignment Concerns: {{alignment_issues}}\n",
        "\n",
        "Based on the above, generate the **improved_code**:\n",
        "```python\n",
        "# Python code implementation of the AIME problem solution, improved based on critique.\n",
        "\n",
        "# Follow the exact reasoning steps shown in the Chain of Thought\n",
        "# Use appropriate Python libraries (math, itertools, etc.) if needed\n",
        "import math\n",
        "import itertools\n",
        "# import numpy as np # Include if needed based on the problem\n",
        "\n",
        "# Include comments explaining key steps\n",
        "# Be mathematically rigorous without shortcuts\n",
        "# Is self-contained and can be executed independently\n",
        "\n",
        "# --- Start of improved implementation ---\n",
        "# Implement the solution, addressing the critique points and edge cases.\n",
        "# Ensure mathematical rigor and correctness.\n",
        "\n",
        "# [Generate the improved Python code here]\n",
        "\n",
        "# --- End of improved implementation ---\n",
        "\n",
        "# Assign final computed output to variable `calculated_result`\n",
        "# Ensure robust handling of potential issues like empty lists or edge cases.\n",
        "# Implement proper error management (avoiding sys.exit()).\n",
        "# Avoid commented out code unless strictly necessary for explanation.\n",
        "\n",
        "# Mandatory Final Verification: Assert that the calculated result matches the provided correct answer.\n",
        "assert calculated_result == {{answer}}\n",
        "    \"\"\"\n",
        "\n",
        "    code_regenerator = StructuredLLM(\n",
        "        model_name=google_reasoning_model,\n",
        "        prompt=regenerate_prompt,\n",
        "        output_schema=CodeRegeneratorSchema,\n",
        "    )\n",
        "\n",
        "    output = await code_regenerator.run(\n",
        "        initial_code = initial_code,\n",
        "        critique = critique,\n",
        "        edge_cases_missing=edge_cases_missing,\n",
        "        alignment_issues = alignment_issues,\n",
        "        problem = problem,\n",
        "        reasoning = reasoning,\n",
        "        answer = answer\n",
        "\n",
        "    )\n",
        "    result = output.data[0]\n",
        "\n",
        "    return [{\n",
        "        \"improved_code\": result['improved_code'],\n",
        "        \"problem\": problem,\n",
        "        \"reasoning\": reasoning,\n",
        "        \"topic\": topic,\n",
        "        \"answer\": answer,\n",
        "        \"cot_type\": cot_type,\n",
        "    }]\n",
        "\n",
        "# Step 4: Data Factory → Execute and verify final code\n",
        "@data_factory_with_default(max_concurrency = 50)\n",
        "async def execute_final_code(improved_code: str, problem: str, reasoning: str, topic: str, answer: str, cot_type: str):\n",
        "    execute_prompt = f\"\"\"\n",
        "    Execute the following code:\n",
        "    {improved_code}\n",
        "    \"\"\"\n",
        "\n",
        "    executor_agent = Agent(\n",
        "        name=\"Tool caller\",\n",
        "        output_type=CodeExecutorSchema,\n",
        "        tools=[execute_code_with_timeout],\n",
        "        model=model_name_used,\n",
        "        model_settings=ModelSettings(tool_choice=\"required\"),\n",
        "        tool_use_behavior=\"stop_on_first_tool\"\n",
        "    )\n",
        "\n",
        "    run_result = await Runner.run(executor_agent, input=execute_prompt)\n",
        "\n",
        "    verification_prompt = f\"\"\"\n",
        "Compare the value of `calculated_result` with the value of `correct_answer`.\n",
        "If `calculated_result' is the same or equal to  `correct_answer` set `verfied` to True else return False.\n",
        "\n",
        "calculated_result: {run_result.final_output['calculated_result']}\n",
        "correct_answer: {answer}\n",
        "\n",
        "verified:\n",
        "    \"\"\"\n",
        "\n",
        "    answer_verification_agent = Agent(\n",
        "        name=\"Answer Verifier\",\n",
        "        output_type=AnswerVerfierSchema,\n",
        "        model=model_name_used,\n",
        "    )\n",
        "\n",
        "    verification_result = await Runner.run(answer_verification_agent, input=verification_prompt)\n",
        "\n",
        "\n",
        "    output = run_result.final_output\n",
        "    output.update({\n",
        "        \"problem\": problem,\n",
        "        \"topic\": topic,\n",
        "        \"cot_type\": cot_type,\n",
        "        \"reasoning\": reasoning,\n",
        "        \"correct_answer\": answer,\n",
        "        \"verfied\": verification_result.final_output.verified,\n",
        "        \"calculated_result\": run_result.final_output['calculated_result']\n",
        "    })\n",
        "\n",
        "    return [output]\n",
        "\n",
        "@function_tool\n",
        "async def execute_code_with_timeout(code: str):\n",
        "    import multiprocessing\n",
        "    import asyncio\n",
        "\n",
        "    def worker(code_to_run):\n",
        "        manager = multiprocessing.Manager()\n",
        "        shared = manager.dict()\n",
        "\n",
        "        def run_user_code():\n",
        "            safe_globals = {\n",
        "                \"__builtins__\": __builtins__,\n",
        "            }\n",
        "            local_vars = safe_globals\n",
        "            clean_code = code_to_run.replace('\\x00', '')  # sanitize null bytes\n",
        "\n",
        "            try:\n",
        "                exec(clean_code, local_vars, local_vars)\n",
        "                shared['calculated_result'] = local_vars['calculated_result']\n",
        "            except Exception as e:\n",
        "                print(f\"Exception during code execution: {e}\")\n",
        "                shared['calculated_result'] = local_vars.get('calculated_result', \"\")\n",
        "\n",
        "        p = multiprocessing.Process(target=run_user_code)\n",
        "        p.start()\n",
        "        p.join(timeout=20)\n",
        "        if p.is_alive():\n",
        "            p.terminate()\n",
        "            p.join()\n",
        "            return {\"finished_run\": False, \"improved_code\" : code_to_run, \"calculated_result\": \"\" }\n",
        "\n",
        "        return {\n",
        "            \"finished_run\": True,\n",
        "            \"improved_code\" : code_to_run,\n",
        "            \"calculated_result\": shared.get('calculated_result', \"\")\n",
        "        }\n",
        "\n",
        "    loop = asyncio.get_event_loop()\n",
        "    result = await loop.run_in_executor(None, worker, code)\n",
        "    return result\n",
        "\n",
        "\n",
        "# Step 1: Define your desired structured output\n",
        "class FeedbackAndRewriteSchema(BaseModel):\n",
        "    topic: str\n",
        "    problem: str\n",
        "    reasoning: str\n",
        "\n",
        "\n",
        "@data_factory_with_default()\n",
        "async def feedback_and_rewrite(topic: str, problem: str, reasoning: str, verified: bool, correct_answer: str, cot_type: str, code: str):\n",
        "    # Step 1: Critique and Rewrite the Reasoning\n",
        "    feedback_prompt = \"\"\"\n",
        "    Review the problem and the current solution attempt below.\n",
        "\n",
        "    1. Check if the reasoning leads to the correct answer.\n",
        "    2. If mistakes exist, fix them and rewrite the reasoning.\n",
        "    3. Keep a clear, step-by-step explanation.\n",
        "\n",
        "    Problem:\n",
        "    {{problem}}\n",
        "\n",
        "    Current Reasoning:\n",
        "    {{reasoning}}\n",
        "\n",
        "    Verified Correct Answer:\n",
        "    {{correct_answer}}\n",
        "    \"\"\"\n",
        "\n",
        "    feedback_agent = Agent(\n",
        "        name=\"Feedback and Rewrite\",\n",
        "        output_type=FeedbackAndRewriteSchema,\n",
        "        model=model_name_used,\n",
        "    )\n",
        "\n",
        "    feedback_run = await Runner.run(feedback_agent, input=feedback_prompt)\n",
        "    rewritten_reasoning = feedback_run.final_output.reasoning\n",
        "\n",
        "    # Step 2: Generate Initial Code from Rewritten Reasoning\n",
        "    initial_code_output = await generate_initial_code.run(\n",
        "        topic=topic,\n",
        "        problem=problem,\n",
        "        reasoning=rewritten_reasoning,\n",
        "        answer=correct_answer,\n",
        "        cot_type=cot_type\n",
        "    )\n",
        "\n",
        "    # Step 3: Critique the Newly Generated Code\n",
        "    critique_output = await critique_generated_code.run(\n",
        "        initial_code=initial_code_output[0][\"initial_code\"],\n",
        "        problem=problem,\n",
        "        reasoning=rewritten_reasoning,\n",
        "        topic=topic,\n",
        "        answer=correct_answer,\n",
        "        cot_type=cot_type\n",
        "    )\n",
        "\n",
        "    # Step 4: Regenerate the Code based on Critique\n",
        "    regenerate_output = await regenerate_code.run(\n",
        "        initial_code=critique_output[0][\"initial_code\"],\n",
        "        critique=critique_output[0][\"critique\"],\n",
        "        edge_cases_missing=critique_output[0][\"edge_cases_missing\"],\n",
        "        alignment_issues=critique_output[0][\"alignment_issues\"],\n",
        "        problem=problem,\n",
        "        reasoning=rewritten_reasoning,\n",
        "        topic=topic,\n",
        "        answer=correct_answer,\n",
        "        cot_type=cot_type\n",
        "    )\n",
        "\n",
        "    # Step 5: Execute and Verify the Final Code\n",
        "    final_execution_output = await execute_final_code.run(\n",
        "        improved_code=regenerate_output[0][\"improved_code\"],\n",
        "        problem=problem,\n",
        "        reasoning=rewritten_reasoning,\n",
        "        topic=topic,\n",
        "        answer=correct_answer,\n",
        "        cot_type=cot_type\n",
        "    )\n",
        "\n",
        "    return final_execution_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYG-QGQlS-hi"
      },
      "source": [
        "# Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "id": "ASIQGx0zCYkw"
      },
      "outputs": [],
      "source": [
        "topics = generate_topic.run(num_records=500)\n",
        "print(topics)\n",
        "print(len(topics))\n",
        "print(\"DONE WITH TOPICS\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8M7Avex8yQQH",
        "outputId": "9cdedd23-7876-48e6-d0de-8bc68b4a947c"
      },
      "outputs": [],
      "source": [
        "subtopics = generate_sub_topics.run(topics[125:])\n",
        "print(subtopics)\n",
        "print(len(subtopics))\n",
        "print(\"DONE WITH SUBTOPICS\")\n",
        "topics = topics + subtopics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPhQzkUTO6Lz",
        "outputId": "17225b39-cd9a-47e4-a834-fb64b7f1bf74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3732\n"
          ]
        }
      ],
      "source": [
        "print(len(subtopics))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Apj4Hz9pCYc5",
        "outputId": "24ba3a36-d355-4291-b90c-b38e5ce01f3b"
      },
      "outputs": [],
      "source": [
        "problem = generate_problem.run(subtopics)\n",
        "print(problem)\n",
        "print(len(problem))\n",
        "print(\"DONE WITH PROBLEM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6MYGFW5KCYRK",
        "outputId": "a301aa21-0086-4a3d-87a4-229f4c4fad60"
      },
      "outputs": [],
      "source": [
        "short_cot = answer_short_cot.run(problem)\n",
        "print(len(short_cot))\n",
        "print(\"DONE WITH SHORT_COT\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uuh3dVeGCXwy",
        "outputId": "118013d4-3223-4f7a-c441-a7d51e2b20da"
      },
      "outputs": [],
      "source": [
        "inital_code_gen = generate_initial_code.run(short_cot)\n",
        "print(len(inital_code_gen))\n",
        "print(\"DONE WITH CODE EXECUTION\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Me47XqB_RgPF",
        "outputId": "31d83bb5-89a4-43e1-9ba7-af8c0ed9ee65"
      },
      "outputs": [],
      "source": [
        "critique = critique_generated_code.run(inital_code_gen)\n",
        "print(len(critique))\n",
        "print(\"DONE WITH CODE EXECUTION\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JnYGpk9tRmN1",
        "outputId": "36ce9d3a-853b-46fb-e83a-72cb3494c47c"
      },
      "outputs": [],
      "source": [
        "re_generated_code = regenerate_code.run(critique)\n",
        "print(len(re_generated_code))\n",
        "print(\"DONE WITH CODE EXECUTION\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xEH6a7YERyID",
        "outputId": "5af0df24-ac6b-471b-b2d5-0128b006ddc9"
      },
      "outputs": [],
      "source": [
        "final_code_exec = execute_final_code.run(re_generated_code)\n",
        "print(len(final_code_exec))\n",
        "print(\"DONE WITH CODE EXECUTION\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Remove all unverified entries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfXYlY7UCgnE",
        "outputId": "c1c88486-837c-4998-8c18-c71b8c41fc69"
      },
      "outputs": [],
      "source": [
        "all_re_written_cots = []\n",
        "\n",
        "# Start with only unverified entries (string comparison)\n",
        "unverified_entries = [entry for entry in final_code_exec if entry.get(\"verfied\") == False]\n",
        "\n",
        "verified_entries = [entry for entry in final_code_exec if entry.get(\"verfied\") == True]\n",
        "\n",
        "print(\"VERIFIED ENTRIES: \" + str(len(verified_entries)))\n",
        "\n",
        "print(\"UNVERIFIED ENTRIES: \" + str(len(unverified_entries)))\n",
        "\n",
        "if unverified_entries:\n",
        "    # Run feedback and rewrite on the current batch of unverified entries\n",
        "    rewritten_batch = feedback_and_rewrite.run(unverified_entries)\n",
        "\n",
        "    # Collect verified rewrites\n",
        "    verified_batch = [rewritten for rewritten in rewritten_batch if rewritten.get(\"verified\") == \"True\"]\n",
        "    all_re_written_cots.extend(verified_batch)\n",
        "\n",
        "    # Remove verified entries from the current unverified list\n",
        "    unverified_entries = [rewritten for rewritten in rewritten_batch if rewritten.get(\"verified\") == \"False\"]\n",
        "    print(\"ALL REWRITTEN ENTRIES: \" + str(len(all_re_written_cots)))\n",
        "\n",
        "verified_entries = verified_entries + all_re_written_cots\n",
        "print(verified_entries)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMGLytyIS2Xj"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "XXcEExUEgWWs",
        "fBC0Q7IwgZKW",
        "YBNBslDchCYx"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
